{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources Used\n",
    "- wget.download('https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py')\n",
    "- Setup https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "SCRIPTS_PATH = 'Tensorflow/scripts'\n",
    "APIMODEL_PATH = 'Tensorflow/models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    {'name':'Hola', 'id':1},\n",
    "    {'name':'Gracias', 'id':2},\n",
    "    {'name':'Si', 'id':3},\n",
    "    {'name':'No', 'id':4},\n",
    "    {'name':'Te amo', 'id':5}\n",
    "    ]\n",
    "\n",
    "with open(ANNOTATION_PATH + '/label_map.pbtxt', 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n",
      "CPU times: user 87.5 ms, sys: 4.46 ms, total: 92 ms\n",
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x{IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download TF Models Pretrained Models from Tensorflow Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'models' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow && git clone https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget.download('http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz')\n",
    "#!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz {PRETRAINED_MODEL_PATH}\n",
    "#!cd {PRETRAINED_MODEL_PATH} && tar -zxvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'señas_uam_0_1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘Tensorflow/workspace/models/señas_uam_0_1’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir {'Tensorflow/workspace/models/'+CUSTOM_MODEL_NAME}\n",
    "!cp {PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'} {MODEL_PATH+'/'+CUSTOM_MODEL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 22:10:30.993679: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-05 22:10:31.294351: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-05 22:10:31.295991: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 22:10:32.615564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/workspace/models/señas_uam_0_1/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "print(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\",\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = 5\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n",
    "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/señas_uam_0_1 --pipeline_config_path=Tensorflow/workspace/models/señas_uam_0_1/pipeline.config --num_train_steps=5000\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"python {}/research/object_detection/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config --num_train_steps=5000\"\"\".format(APIMODEL_PATH, MODEL_PATH,CUSTOM_MODEL_NAME,MODEL_PATH,CUSTOM_MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join('Tensorflow/workspace/models/señas_uam_0_1/', 'ckpt-21')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.checkpoint.checkpoint.Checkpoint object at 0x7fc87703f7c0>\n"
     ]
    }
   ],
   "source": [
    "print(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.InitializationOnlyStatus at 0x7fc8484c5e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.restore(tf.train.latest_checkpoint(os.path.join('Tensorflow/workspace/models/señas_uam_0_1/', 'ckpt-21'))).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got <tensorflow.python.checkpoint.checkpoint.Checkpoint object at 0x7fc8484b9250>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tf\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload(ckpt)\n",
      "File \u001b[0;32m~/Documents/Git/RealTimeObjectDetection/.venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:858\u001b[0m, in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[1;32m    857\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[0;32m--> 858\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    859\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/Git/RealTimeObjectDetection/.venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:963\u001b[0m, in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39mif\u001b[39;00m tags \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tags, \u001b[39mset\u001b[39m):\n\u001b[1;32m    959\u001b[0m   \u001b[39m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[1;32m    960\u001b[0m   \u001b[39m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[1;32m    961\u001b[0m   tags \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(tags)\n\u001b[1;32m    962\u001b[0m saved_model_proto, debug_info \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 963\u001b[0m     loader_impl\u001b[39m.\u001b[39;49mparse_saved_model_with_debug_info(export_dir))\n\u001b[1;32m    965\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(saved_model_proto\u001b[39m.\u001b[39mmeta_graphs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     saved_model_proto\u001b[39m.\u001b[39mmeta_graphs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mHasField(\u001b[39m\"\u001b[39m\u001b[39mobject_graph_def\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    967\u001b[0m   metrics\u001b[39m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[0;32m~/Documents/Git/RealTimeObjectDetection/.venv/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py:58\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[1;32m     46\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m   saved_model \u001b[39m=\u001b[39m parse_saved_model(export_dir)\n\u001b[1;32m     60\u001b[0m   debug_info_path \u001b[39m=\u001b[39m file_io\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     61\u001b[0m       path_helpers\u001b[39m.\u001b[39mget_debug_dir(export_dir),\n\u001b[1;32m     62\u001b[0m       constants\u001b[39m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[1;32m     63\u001b[0m   debug_info \u001b[39m=\u001b[39m graph_debug_info_pb2\u001b[39m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[0;32m~/Documents/Git/RealTimeObjectDetection/.venv/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py:90\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reads the savedmodel.pb or savedmodel.pbtxt file containing `SavedModel`.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39m  IOError: If the file does not exist, or cannot be successfully parsed.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39m# Build the path to the SavedModel in pbtxt format.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m path_to_pbtxt \u001b[39m=\u001b[39m file_io\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m---> 90\u001b[0m     compat\u001b[39m.\u001b[39;49mas_bytes(compat\u001b[39m.\u001b[39;49mpath_to_str(export_dir)),\n\u001b[1;32m     91\u001b[0m     compat\u001b[39m.\u001b[39mas_bytes(constants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001b[1;32m     92\u001b[0m \u001b[39m# Build the path to the SavedModel in pb format.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m path_to_pb \u001b[39m=\u001b[39m file_io\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     94\u001b[0m     compat\u001b[39m.\u001b[39mas_bytes(compat\u001b[39m.\u001b[39mpath_to_str(export_dir)),\n\u001b[1;32m     95\u001b[0m     compat\u001b[39m.\u001b[39mas_bytes(constants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PB))\n",
      "File \u001b[0;32m~/Documents/Git/RealTimeObjectDetection/.venv/lib/python3.8/site-packages/tensorflow/python/util/compat.py:85\u001b[0m, in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[39mreturn\u001b[39;00m bytes_or_text\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mExpected binary or unicode string, got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m     86\u001b[0m                   (bytes_or_text,))\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got <tensorflow.python.checkpoint.checkpoint.Checkpoint object at 0x7fc8484b9250>"
     ]
    }
   ],
   "source": [
    "tf.saved_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'load_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m./Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m checkpoint_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./Tensorflow/workspace/models/señas_uam_0_1/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(checkpoint_path)\n\u001b[1;32m      4\u001b[0m save_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./output/modelo_señas\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39msave(model,save_path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'load_weights'"
     ]
    }
   ],
   "source": [
    "model = tf.saved_model.load(\"./Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\")\n",
    "checkpoint_path = \"./Tensorflow/workspace/models/señas_uam_0_1/\"\n",
    "model.load_weights(checkpoint_path)\n",
    "save_path = \"./output/modelo_señas\"\n",
    "tf.saved_model.save(model,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-06 16:58:27.750866: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-06 16:58:27.786625: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-06 16:58:27.786968: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 16:58:28.558175: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/isur/Documents/Git/RealTimeObjectDetection/.venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0906 16:58:30.518333 140418127636288 deprecation.py:641] From /home/isur/Documents/Git/RealTimeObjectDetection/.venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "I0906 16:58:33.965326 140418127636288 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "I0906 16:58:41.938664 140418127636288 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "I0906 16:58:44.226321 140418127636288 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_predictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\n",
      "I0906 16:58:45.229422 140418127636288 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb51424b220>, because it is not built.\n",
      "W0906 16:58:47.456051 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb51424b220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb504326880>, because it is not built.\n",
      "W0906 16:58:47.708611 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb504326880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504087d90>, because it is not built.\n",
      "W0906 16:58:47.708770 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504087d90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504087220>, because it is not built.\n",
      "W0906 16:58:47.708828 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504087220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb5040bc9d0>, because it is not built.\n",
      "W0906 16:58:47.708880 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb5040bc9d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5040bc610>, because it is not built.\n",
      "W0906 16:58:47.708934 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5040bc610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb5040bc3d0>, because it is not built.\n",
      "W0906 16:58:47.708984 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb5040bc3d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb5040bc280>, because it is not built.\n",
      "W0906 16:58:47.709034 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb5040bc280>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5043df880>, because it is not built.\n",
      "W0906 16:58:47.709084 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5043df880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504639640>, because it is not built.\n",
      "W0906 16:58:47.709140 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504639640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb504639550>, because it is not built.\n",
      "W0906 16:58:47.709189 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fb504639550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5047f3130>, because it is not built.\n",
      "W0906 16:58:47.709239 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5047f3130>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504153100>, because it is not built.\n",
      "W0906 16:58:47.709290 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504153100>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5041536a0>, because it is not built.\n",
      "W0906 16:58:47.709341 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5041536a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50413ecd0>, because it is not built.\n",
      "W0906 16:58:47.709391 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50413ecd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50413e2b0>, because it is not built.\n",
      "W0906 16:58:47.709440 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50413e2b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb5183f2070>, because it is not built.\n",
      "W0906 16:58:47.709490 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb5183f2070>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50476d2e0>, because it is not built.\n",
      "W0906 16:58:47.709539 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50476d2e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50413a2b0>, because it is not built.\n",
      "W0906 16:58:47.709589 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50413a2b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50413a670>, because it is not built.\n",
      "W0906 16:58:47.709638 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50413a670>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50413a400>, because it is not built.\n",
      "W0906 16:58:47.709688 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50413a400>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504077ca0>, because it is not built.\n",
      "W0906 16:58:47.709739 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504077ca0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb4f067fbe0>, because it is not built.\n",
      "W0906 16:58:47.709789 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb4f067fbe0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb4f06f1130>, because it is not built.\n",
      "W0906 16:58:47.709878 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb4f06f1130>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb4f06f1430>, because it is not built.\n",
      "W0906 16:58:47.709935 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb4f06f1430>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb4f06f1dc0>, because it is not built.\n",
      "W0906 16:58:47.709985 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb4f06f1dc0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb4f06f1f10>, because it is not built.\n",
      "W0906 16:58:47.710045 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb4f06f1f10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb4f06f19a0>, because it is not built.\n",
      "W0906 16:58:47.710096 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb4f06f19a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb4f06f1ac0>, because it is not built.\n",
      "W0906 16:58:47.710146 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb4f06f1ac0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504084040>, because it is not built.\n",
      "W0906 16:58:47.710199 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504084040>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504183910>, because it is not built.\n",
      "W0906 16:58:47.710247 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504183910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504092fa0>, because it is not built.\n",
      "W0906 16:58:47.710297 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504092fa0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50425d160>, because it is not built.\n",
      "W0906 16:58:47.710351 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50425d160>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50425da60>, because it is not built.\n",
      "W0906 16:58:47.710405 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50425da60>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50425d340>, because it is not built.\n",
      "W0906 16:58:47.710459 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb50425d340>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50425db50>, because it is not built.\n",
      "W0906 16:58:47.710509 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb50425db50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb5042252b0>, because it is not built.\n",
      "W0906 16:58:47.710561 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb5042252b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5042173d0>, because it is not built.\n",
      "W0906 16:58:47.710611 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb5042173d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb5043d6130>, because it is not built.\n",
      "W0906 16:58:47.710662 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb5043d6130>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504080370>, because it is not built.\n",
      "W0906 16:58:47.710710 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504080370>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504080550>, because it is not built.\n",
      "W0906 16:58:47.710774 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504080550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504080460>, because it is not built.\n",
      "W0906 16:58:47.710828 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504080460>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504080880>, because it is not built.\n",
      "W0906 16:58:47.710876 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504080880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504212730>, because it is not built.\n",
      "W0906 16:58:47.710927 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fb504212730>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504212a30>, because it is not built.\n",
      "W0906 16:58:47.710976 140418127636288 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fb504212a30>, because it is not built.\n",
      "I0906 16:58:57.410767 140418127636288 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: output_model/saved_model/assets\n",
      "I0906 16:59:02.055353 140418127636288 builder_impl.py:804] Assets written to: output_model/saved_model/assets\n",
      "I0906 16:59:02.326703 140418127636288 fingerprinting_utils.py:48] Writing fingerprint to output_model/saved_model/fingerprint.pb\n",
      "INFO:tensorflow:Writing pipeline config file to output_model/pipeline.config\n",
      "I0906 16:59:02.686783 140418127636288 config_util.py:253] Writing pipeline config file to output_model/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python Tensorflow/models/research/object_detection/exporter_main_v2.py --output_directory output_model --pipeline_config_path Tensorflow/workspace/models/señas_uam_0_1/pipeline.config --trained_checkpoint_dir Tensorflow/workspace/models/señas_uam_0_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-06 16:59:46.233122: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-06 16:59:46.267051: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-06 16:59:46.267348: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 16:59:46.997004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2023-09-06 16:59:47,919 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2023-09-06 16:59:54,052 - INFO - Signatures found in model: [serving_default].\n",
      "2023-09-06 16:59:54,052 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2023-09-06 16:59:54,053 - INFO - Output names: ['detection_anchor_indices', 'detection_boxes', 'detection_classes', 'detection_multiclass_scores', 'detection_scores', 'num_detections', 'raw_detection_boxes', 'raw_detection_scores']\n",
      "2023-09-06 16:59:54,054 - WARNING - Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-09-06 16:59:54.110713: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-09-06 16:59:54.110844: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-09-06 16:59:56.711458: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-09-06 16:59:56.711748: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-09-06 16:59:57,687 - INFO - Using tensorflow=2.13.0, onnx=1.14.1, tf2onnx=1.15.1/37820d\n",
      "2023-09-06 16:59:57,687 - INFO - Using opset <onnx, 15>\n",
      "2023-09-06 16:59:57,955 - INFO - Computed 0 values for constant folding\n",
      "2023-09-06 16:59:57,958 - INFO - Computed 0 values for constant folding\n",
      "2023-09-06 16:59:58.018340: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-09-06 16:59:58,072 - INFO - Computed 2 values for constant folding\n",
      "2023-09-06 16:59:58,356 - INFO - folding node using tf type=Select, name=StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Select_1\n",
      "2023-09-06 16:59:58,356 - INFO - folding node using tf type=Select, name=StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Select_8\n",
      "2023-09-06 16:59:59,483 - INFO - Optimizing ONNX model\n",
      "2023-09-06 17:00:08,012 - INFO - After optimization: BatchNormalization -52 (76->24), Cast -87 (176->89), Const -931 (1241->310), Identity -32 (32->0), Less -1 (9->8), Mul -2 (49->47), Placeholder -2 (6->4), ReduceSum -5 (6->1), Reshape -76 (109->33), Shape -6 (25->19), Slice -9 (52->43), Squeeze -11 (56->45), Sub -5 (32->27), Transpose -434 (459->25), Unsqueeze -20 (66->46)\n",
      "2023-09-06 17:00:08,089 - INFO - \n",
      "2023-09-06 17:00:08,089 - INFO - Successfully converted TensorFlow model output_model/saved_model to ONNX\n",
      "2023-09-06 17:00:08,089 - INFO - Model inputs: ['input_tensor']\n",
      "2023-09-06 17:00:08,089 - INFO - Model outputs: ['detection_anchor_indices', 'detection_boxes', 'detection_classes', 'detection_multiclass_scores', 'detection_scores', 'num_detections', 'raw_detection_boxes', 'raw_detection_scores']\n",
      "2023-09-06 17:00:08,089 - INFO - ONNX model is saved at modelo_señas.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --saved-model output_model/saved_model --output modelo_señas.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Detect in Real-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'capture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m capture\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'capture' is not defined"
     ]
    }
   ],
   "source": [
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup capture\n",
    "cap = cv2.VideoCapture(0,cv2.CAP_V4L2)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.5,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = detect_fn(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
